{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_load = pd.read_parquet(r'old/data/load_profiles.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_incomplete_days(df):\n",
    "    df_temp = df.groupby('date').count()\n",
    "    incompleteDays = df_temp[(df_temp < 24).any(axis = 1)].index\n",
    "    df = df.loc[~df['date'].isin(incompleteDays)]\n",
    "    incompleteDays_list = [item.strftime('%Y-%m-%d')for item in incompleteDays.tolist()]\n",
    "    print(f'The following days were removed: {incompleteDays_list}')\n",
    "    return df\n",
    "\n",
    "df_load_2 = remove_incomplete_days(df_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, cat, optim, full, randn, no_grad\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, dimLatent, classCount, dimEmbedding):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dimLatent = dimLatent\n",
    "        self.classCount = classCount\n",
    "        self.dimEmbedding = dimEmbedding    #dimension of the embedding tensor\n",
    "        self.labelEmbedding = nn.Embedding(num_embeddings = self.classCount, embedding_dim = dimEmbedding)\n",
    "        self.model = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Linear(in_features = self.dimLatent + self.dimEmbedding, out_features = 64),\n",
    "            #nn.ReLU(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            # 2nd layer\n",
    "            nn.Linear(in_features = 64, out_features = 128),\n",
    "            #nn.ReLU(),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            # 3rd layer\n",
    "            nn.Linear(in_features = 128, out_features = 24),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise, labels):\n",
    "        x = self.model(cat((self.labelEmbedding(labels), noise), -1))   #apply model to concatenated tensor (fixed label tensor + noise tensor)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, featureCount, classCount, dimEmbedding):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.featureCount = featureCount\n",
    "        self.classCount = classCount\n",
    "        self.dimEmbedding = dimEmbedding\n",
    "        self.labelEmbedding = nn.Embedding(num_embeddings = self.classCount, embedding_dim = dimEmbedding)\n",
    "        self.model = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Linear(in_features = self.featureCount + self.dimEmbedding, out_features = 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            # 2nd layer\n",
    "            nn.Linear(in_features = 128, out_features = 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            # 3rd layer\n",
    "            nn.Linear(in_features = 64, out_features = 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, data, labels):\n",
    "        bool_ = self.model(cat((data, self.labelEmbedding(labels)), -1))\n",
    "        return bool_\n",
    "\n",
    "\n",
    "class GAN(object):\n",
    "    def __init__(self, device, dataLoader, dimLatent, featureCount, classCount, dimEmbedding, lr, maxNorm, epochCount, testLabel = None, exampleCount = 3):\n",
    "        self.device = device\n",
    "        self.dataLoader = dataLoader\n",
    "        self.dimLatent = dimLatent\n",
    "        self.featureCount = featureCount\n",
    "        self.classCount = classCount\n",
    "        self.dimEmbedding = dimEmbedding\n",
    "        self.lr = lr\n",
    "        self.maxNorm = maxNorm\n",
    "        self.epochCount = epochCount\n",
    "        self.testLabel = testLabel\n",
    "        self.exampleCount = exampleCount\n",
    "\n",
    "        # Initialize generator\n",
    "        self.Gen = Generator(dimLatent, classCount, dimEmbedding)\n",
    "        self.Gen.to(self.device)\n",
    "\n",
    "        # Initialize discriminator\n",
    "        self.Dis = Discriminator(featureCount, classCount, dimEmbedding)\n",
    "        self.Dis.to(self.device)\n",
    "    \n",
    "        # Initialize optimizers\n",
    "        self.optimGen = optim.Adam(params = self.Gen.parameters(), lr = self.lr)\n",
    "        self.optimDis = optim.Adam(params = self.Dis.parameters(), lr = self.lr)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "        self.df_loss = pd.DataFrame(\n",
    "            columns = [\n",
    "                'epoch',\n",
    "                'batch index',\n",
    "                'discriminator loss (real data)',\n",
    "                'discriminator loss (fake data)',\n",
    "                'discriminator loss',\n",
    "                'generator loss',\n",
    "                'discriminator gradient norm',\n",
    "                'generator gradient norm'\n",
    "            ])\n",
    "        self.iterCount = 0\n",
    "        if isinstance(testLabel, int):\n",
    "            self.noiseFixed = randn(self.exampleCount, dimLatent, device = device)\n",
    "            self.labelsFixed = full(size = (self.exampleCount,), fill_value = self.testLabel, device = self.device, dtype = torch.int32)\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.epochCount)):\n",
    "            for batchIdx, (data, target) in enumerate(self.dataLoader): #target = actual (real) label\n",
    "                data = data.to(device = self.device, dtype = torch.float32)\n",
    "                target = target.to(device = self.device, dtype = torch.int32)\n",
    "\n",
    "                # Train discriminator with real data\n",
    "                self.Dis.zero_grad()                                                                                            #set the gradients to zero for every mini-batch\n",
    "                yReal = self.Dis(data, target)                                                                                  #train discriminator with real data\n",
    "                labelReal = full(size = (data.size(0), 1), fill_value = 1, device = self.device, dtype = torch.float32)         #a tensor containing only ones\n",
    "                lossDisReal = self.criterion(yReal, labelReal)                                                                  #calculate the loss\n",
    "                lossDisReal.backward()                                                                                          #calculate new gradients\n",
    "\n",
    "                # Train discriminator with fake data\n",
    "                noise = randn(data.size(0), self.dimLatent, device = self.device)                                               #create a tensor filled with random numbers\n",
    "                randomLabelFake = torch.randint(low = 0, high = self.classCount, size = (data.size(0),), device = self.device)  #random labels needed in addition to the noise\n",
    "                labelFake = full(size = (data.size(0), 1), fill_value = 0, device = self.device, dtype = torch.float32)         #a tensor containing only zeros\n",
    "                xFake = self.Gen(noise, randomLabelFake)                                                                        #create fake data from noise + random labels with generator\n",
    "                yFake = self.Dis(xFake.detach(), randomLabelFake)                                                               #let the discriminator label the fake data (`.detach()` creates a copy of the tensor)\n",
    "                lossDisFake = self.criterion(yFake, labelFake)\n",
    "                lossDisFake.backward()\n",
    "\n",
    "                lossDis = (lossDisReal + lossDisFake)                                                                           #compute the total discriminator loss\n",
    "                grad_norm_dis = torch.nn.utils.clip_grad_norm_(self.Dis.parameters(), max_norm = self.maxNorm)                  #gradient clipping (large max_norm to avoid actual clipping)\n",
    "                self.optimDis.step()                                                                                            #update the discriminator\n",
    "\n",
    "                # Train generator (now that we fed the discriminator with fake data)\n",
    "                self.Gen.zero_grad()\n",
    "                yFake_2 = self.Dis(xFake, randomLabelFake)                                                                      #let the discriminator label the fake data (now that the discriminator is updated)\n",
    "                lossGen = self.criterion(yFake_2, labelReal)                                                                    #calculate the generator loss (small if the discriminator thinks that `yFake_2 == labelReal`)\n",
    "                lossGen.backward()\n",
    "                grad_norm_gen = torch.nn.utils.clip_grad_norm_(self.Gen.parameters(), max_norm = self.maxNorm)\n",
    "                self.optimGen.step()\n",
    "\n",
    "                # Log the progress\n",
    "                self.df_loss.loc[len(self.df_loss)] = [\n",
    "                    epoch,\n",
    "                    batchIdx,\n",
    "                    lossDisReal.detach().cpu().numpy(),\n",
    "                    lossDisFake.detach().cpu().numpy(),\n",
    "                    lossDis.detach().cpu().numpy(),\n",
    "                    lossGen.detach().cpu().numpy(),\n",
    "                    grad_norm_dis.detach().cpu().numpy(),\n",
    "                    grad_norm_gen.detach().cpu().numpy()\n",
    "                ]\n",
    "                if self.iterCount % int(self.epochCount*len(self.dataLoader)/10) == 0 or self.iterCount == self.epochCount*len(self.dataLoader) - 1:\n",
    "                    print(f'training: {int(self.iterCount/(self.epochCount*len(self.dataLoader))*100)} %')\n",
    "                    if isinstance(testLabel, int):\n",
    "                        with no_grad():\n",
    "                            xFakeTest = self.Gen(self.noiseFixed, self.labelsFixed)\n",
    "                            yFakeTest = self.Dis(xFakeTest, self.labelsFixed)\n",
    "                            plt.figure(figsize = (4, 3), facecolor = 'w')\n",
    "                            plt.plot(xFakeTest.detach().cpu().T)\n",
    "                            plt.title(f'labels: {self.labelsFixed.numpy()}\\ndiscriminator: {yFakeTest.detach().cpu().numpy().reshape(-1).round(4)}')\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig(f'training_{int(self.iterCount/(self.epochCount*len(self.dataLoader))*100)}_%.png')\n",
    "                            plt.show()\n",
    "                            print(aaa)\n",
    "                self.iterCount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare profile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "profile = '16'\n",
    "\n",
    "df_profile = df_load[['date', 'month', 'hour of the day', profile]]\n",
    "\n",
    "label_dict = {}\n",
    "idx = 0\n",
    "\n",
    "for item in df_profile['date'].unique():\n",
    "    if item not in label_dict:\n",
    "        label_dict[item] = idx\n",
    "        idx += 1\n",
    "\n",
    "df_profile = df_profile.pivot_table(columns = 'hour of the day', index = 'date', values = profile)\n",
    "\n",
    "df_profile.reset_index(inplace = True)\n",
    "\n",
    "df_profile['date'] = df_profile['date'].map(label_dict)\n",
    "\n",
    "labels = df_profile['date'].to_numpy()\n",
    "\n",
    "df_profile.drop(columns = 'date', inplace = True)\n",
    "\n",
    "samples = df_profile.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scale data to range -1, 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.preprocessing import minmax_scale, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "samplesScaled = scaler.fit_transform(samples.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesScaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run GAN (**can be skipped, trained model can be loaded futher down below**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('GPU is used.')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU is used.')\n",
    "\n",
    "dataset = TensorDataset(torch.Tensor(samplesScaled), torch.Tensor(labels))\n",
    "dataLoader = DataLoader(dataset)\n",
    "dimLatent = 32\n",
    "featureCount = samplesScaled.shape[1]\n",
    "classCount = len(set(labels))\n",
    "dimEmbedding = classCount\n",
    "lr = 2*1e-4/3\n",
    "maxNorm = 1e6\n",
    "epochCount = 200\n",
    "testLabel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAN(device, dataLoader, dimLatent, featureCount, classCount, dimEmbedding, lr, maxNorm, epochCount, testLabel)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exampleCount = 3\n",
    "label = 0\n",
    "\n",
    "noise = randn(exampleCount, dimLatent, device = device)\n",
    "label_ = full(size = (exampleCount,), fill_value = label, device = device, dtype = torch.int32)\n",
    "\n",
    "samplesGen = model.Gen(noise, label_).detach().cpu().numpy()\n",
    "\n",
    "plt.plot(samplesGen.T, color = 'green', alpha = 0.5)\n",
    "plt.plot([], color = 'green', label = 'Synthetic')\n",
    "plt.plot(samplesScaled[labels == label].T, color = 'red', label = 'Real', alpha = 0.75)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reverseLabel_dict = {value: key for key, value in label_dict.items()}\n",
    "\n",
    "for item in labels:\n",
    "    label = item\n",
    "    noise = randn(exampleCount, dimLatent, device = device)\n",
    "    label_ = full(size = (exampleCount,), fill_value = label, device = device, dtype = torch.int32)\n",
    "    samplesGen = model.Gen(noise, label_).detach().cpu().numpy()\n",
    "    plt.plot(samplesGen.T, color = 'green', alpha = 0.5)\n",
    "    plt.plot([], color = 'green', label = 'Synthetic')\n",
    "    plt.plot(samplesScaled[labels == label].T, color = 'red', label = 'Real', alpha = 0.75)\n",
    "    plt.legend()\n",
    "    plt.title(reverseLabel_dict[item])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"model_phil.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load('model_phil.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sdmetrics.single_column import KSComplement\n",
    "\n",
    "KSComplement.compute(\n",
    "    real_data=samples.reshape(-1),\n",
    "    synthetic_data=synthSamples.reshape(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sdmetrics.single_column import RangeCoverage\n",
    "\n",
    "RangeCoverage.compute(\n",
    "    real_data=samples.reshape(-1),\n",
    "    synthetic_data=synthSamples.reshape(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_load[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(np.vstack([samples.reshape(-1), synthSamples.reshape(-1)]).T, index=df_load[\"timestamp\"], columns=[\"real\", \"synthetic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_1.real.hist(alpha=0.5)\n",
    "df_1.synthetic.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sdmetrics.visualization import get_column_plot\n",
    "\n",
    "fig = get_column_plot(\n",
    "    real_data=pd.DataFrame(samples.reshape(-1), index=df_load[\"timestamp\"], columns=[\"values\"]),\n",
    "    synthetic_data=pd.DataFrame(synthSamples.reshape(-1), index=df_load[\"timestamp\"], columns=[\"values\"]),\n",
    "    column_name=\"values\",\n",
    "    plot_type='distplot'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_df_loss(col):\n",
    "    model.df_loss[col].astype(float).plot(title = col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_df_loss('generator loss')\n",
    "plot_df_loss('discriminator loss (real data)')\n",
    "plot_df_loss('discriminator loss (fake data)')\n",
    "plot_df_loss('generator gradient norm')\n",
    "plot_df_loss('discriminator gradient norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Save trained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.save(model, 'model_3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create whole profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "synthSamples_list = []\n",
    "\n",
    "for item in labels:\n",
    "    noise = randn(1, dimLatent, device = device)\n",
    "    label_ = full(size = (1,), fill_value = item, device = device, dtype = torch.int32)\n",
    "    samplesGen = model.Gen(noise, label_).detach().cpu().numpy()\n",
    "    synthSamples_list.append(samplesGen)\n",
    "\n",
    "synthSamples = np.vstack(synthSamples_list)\n",
    "\n",
    "synthSamples = scaler.inverse_transform(synthSamples.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (36, 12))\n",
    "plt.plot(synthSamples.reshape(-1), color = 'green', label = 'Synthetic')\n",
    "plt.legend(fontsize = 32)\n",
    "plt.show()\n",
    "plt.figure(figsize = (36, 12))\n",
    "plt.plot(samples.reshape(-1), color = 'red', label = 'Real')\n",
    "plt.legend(fontsize = 32)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "79b4750ed2717c744363ddeeb308685b8aa38c66aec97c408e6db81441baebf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
