{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from preproc import import_and_preprocess_data, create_and_add_datetime_features\n",
    "import json\n",
    "\n",
    "path = r'data/all_load_profiles.json'\n",
    "\n",
    "df_loadProfiles, log_dict = import_and_preprocess_data(path)\n",
    "df_loadProfiles = create_and_add_datetime_features(df_loadProfiles)\n",
    "\n",
    "with open(r'data/preproc_log.json', 'w') as file:\n",
    "    json.dump(log_dict, file)\n",
    "df_loadProfiles.to_parquet(r'data/load_profiles.parquet.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manip import remove_incomplete_days\n",
    "\n",
    "df_loadProfiles = pd.read_parquet(r'data/load_profiles.parquet.gzip')   #import data\n",
    "\n",
    "df_loadProfiles = remove_incomplete_days(df_loadProfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, MinMaxScaler\n",
    "\n",
    "profile = '16'\n",
    "\n",
    "df_profile = df_loadProfiles[['date', 'hour of the day', profile]]\n",
    "df_profile = df_profile.pivot_table(columns = 'hour of the day', index = 'date', values = profile)\n",
    "\n",
    "labels = np.array(range(len(df_profile)))\n",
    "samples = df_profile.to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "samplesScaled = scaler.fit_transform(samples.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "dataset = TensorDataset(torch.Tensor(samplesScaled), torch.Tensor(labels))\n",
    "dataLoader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('GPU is used.')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU is used.')\n",
    "\n",
    "dimLatent = 32\n",
    "featureCount = samplesScaled.shape[1]\n",
    "classCount = len(set(labels))\n",
    "dimEmbedding = classCount\n",
    "lr = 2*1e-4/3\n",
    "maxNorm = 1e6\n",
    "epochCount = 100\n",
    "testLabel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAN import GAN\n",
    "\n",
    "model = GAN(\n",
    "    device = device,\n",
    "    dataLoader = dataLoader,\n",
    "    dimLatent = dimLatent,\n",
    "    featureCount = featureCount,\n",
    "    classCount = classCount,\n",
    "    dimEmbedding = dimEmbedding,\n",
    "    lr = lr,\n",
    "    maxNorm = maxNorm,\n",
    "    epochCount = epochCount,\n",
    "    testLabel = testLabel\n",
    ")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/test_model_2023-11-15.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/test_model_2023-11-15.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DoppelGANger')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79b4750ed2717c744363ddeeb308685b8aa38c66aec97c408e6db81441baebf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
