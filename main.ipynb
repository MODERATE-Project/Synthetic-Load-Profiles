{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from preproc import import_and_preprocess_data, create_and_add_datetime_features\n",
    "import json\n",
    "\n",
    "path = r'data/all_load_profiles.json'\n",
    "\n",
    "df_loadProfiles, log_dict = import_and_preprocess_data(path)\n",
    "df_loadProfiles = create_and_add_datetime_features(df_loadProfiles)\n",
    "\n",
    "with open(r'data/preproc_log.json', 'w') as file:\n",
    "    json.dump(log_dict, file)\n",
    "df_loadProfiles.to_parquet(r'data/load_profiles.parquet.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manip import remove_incomplete_days\n",
    "\n",
    "df_loadProfiles = pd.read_parquet(r'data/load_profiles.parquet.gzip')   #import data\n",
    "\n",
    "df_loadProfiles = remove_incomplete_days(df_loadProfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, MinMaxScaler\n",
    "\n",
    "profile = '16'\n",
    "\n",
    "df_profile = df_loadProfiles[['date', 'hour of the day', profile]]\n",
    "df_profile = df_profile.pivot_table(columns = 'hour of the day', index = 'date', values = profile)\n",
    "\n",
    "labels = np.array(range(len(df_profile)))\n",
    "samples = df_profile.to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "samplesScaled = scaler.fit_transform(samples.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "dataset = TensorDataset(torch.Tensor(samplesScaled), torch.Tensor(labels))\n",
    "dataLoader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('GPU is used.')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU is used.')\n",
    "\n",
    "name = 'model_2023-11-15'\n",
    "dimLatent = 32\n",
    "featureCount = samplesScaled.shape[1]\n",
    "classCount = len(set(labels))\n",
    "dimEmbedding = classCount\n",
    "lr = 2*1e-4/3\n",
    "maxNorm = 1e6\n",
    "epochCount = 250\n",
    "testLabel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAN import GAN\n",
    "\n",
    "model = GAN(\n",
    "    name = name,\n",
    "    device = device,\n",
    "    dataLoader = dataLoader,\n",
    "    dimLatent = dimLatent,\n",
    "    featureCount = featureCount,\n",
    "    classCount = classCount,\n",
    "    dimEmbedding = dimEmbedding,\n",
    "    lr = lr,\n",
    "    maxNorm = maxNorm,\n",
    "    epochCount = epochCount,\n",
    "    testLabel = testLabel\n",
    ")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'models/{model.name}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/model_2023-11-15.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate and visualize synthetic load profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfProfiles = 5\n",
    "\n",
    "synthSamplesScaled_list = [model.generate_sample() for i in range(numberOfProfiles)]\n",
    "synthSamples_list = [scaler.inverse_transform(item.T).T for item in synthSamplesScaled_list]\n",
    "\n",
    "synthSamplesScaled = np.dstack(synthSamplesScaled_list)\n",
    "synthSamples = np.dstack(synthSamples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_synthetic_vs_real_samples\n",
    "\n",
    "plot_synthetic_vs_real_samples(\n",
    "    modelName = 'test_model_2023-11-15',\n",
    "    df_profile = df_profile,\n",
    "    samplesScaled = samplesScaled,\n",
    "    synthSamples = synthSamplesScaled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_losses\n",
    "\n",
    "plot_losses(\n",
    "    model = model,\n",
    "    modelName = 'test_model_2023-11-15'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unfinished**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (36, 12))\n",
    "plt.plot(synthSamples.reshape(-1), color = 'green', label = 'Synthetic')\n",
    "plt.legend(fontsize = 32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30, 12), facecolor = 'w')\n",
    "plt.plot(samples.reshape(-1))\n",
    "plt.title('Real profile', fontsize = 24)\n",
    "plt.savefig('plots/test_model_2023-11-15/real_load_profile.png')\n",
    "plt.close();\n",
    "\n",
    "plt.figure(figsize = (30, 12), facecolor = 'w')\n",
    "plt.plot(synthSamples.reshape(-1, 5), linewidth = 0.25, alpha = 0.5, label = range(synthSamples.shape[2]))\n",
    "plt.title('Synthetic profiles', fontsize = 24)\n",
    "plt.legend( title = 'Profile')\n",
    "plt.savefig('plots/test_model_2023-11-15/synthetic_load_profiles.png')\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DoppelGANger')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79b4750ed2717c744363ddeeb308685b8aa38c66aec97c408e6db81441baebf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
